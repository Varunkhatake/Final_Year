{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec385f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\varun\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b2d3a0-0a6e-4e18-9a6f-92ad921bfac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error loading CSV file: [Errno 2] No such file or directory: 'College_Category_Score_Summary.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "class CollegePredictionSystem:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_data(self, csv_file):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding=\"windows-1252\", on_bad_lines='skip')\n",
    "\n",
    "            # Clean College_Name column\n",
    "            self.data['College_Name'] = self.data['College_Name'].str.strip()\n",
    "\n",
    "            required_columns = ['College_Name', 'Branch_Name', 'Location', 'OPEN_Score']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"‚ùå Error: Missing required columns: {missing_columns}\")\n",
    "                return False\n",
    "\n",
    "            print(f\"‚úÖ Successfully loaded {len(self.data)} records from {csv_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading CSV file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"‚ùå No data loaded. Please load data using load_data() first.\")\n",
    "\n",
    "        categorical_columns = ['Category', 'Branch_Name', 'College_Name', 'Location']\n",
    "        for col in categorical_columns:\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.data[col] = self.encoders[col].fit_transform(self.data[col].astype(str))\n",
    "\n",
    "        print(\"‚úÖ Data preprocessing completed!\")\n",
    "\n",
    "    def transform_scores_by_category(self):\n",
    "        score_columns = {\n",
    "            'OPEN': 'OPEN_Score',\n",
    "            'OBC': 'OBC_Score',\n",
    "            'SC': 'SC_Score',\n",
    "            'ST': 'ST_Score',\n",
    "            'SBC': 'SBC_Score',\n",
    "            'DT/VJ': 'DT/VJ_Score'\n",
    "        }\n",
    "\n",
    "        dfs = []\n",
    "        for category, col in score_columns.items():\n",
    "            temp_df = self.data[['College_Name', 'Branch_Name', 'Location', col]].copy()\n",
    "            temp_df = temp_df.rename(columns={col: 'MHT_CET_Score'})\n",
    "            temp_df['Category'] = category\n",
    "            temp_df = temp_df.dropna(subset=['MHT_CET_Score'])\n",
    "            dfs.append(temp_df)\n",
    "\n",
    "        self.data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.transform_scores_by_category()\n",
    "        self.preprocess_data()\n",
    "\n",
    "        features = ['Category', 'MHT_CET_Score', 'Branch_Name', 'Location']\n",
    "        target = 'College_Name'\n",
    "\n",
    "        X = self.data[features]\n",
    "        y = self.data[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        # üîπ Evaluation Metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"‚úÖ Model trained successfully with accuracy: {accuracy:.2f}\")\n",
    "\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        print(\"\\nüßæ Confusion Matrix:\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=False, cmap='Blues', fmt='d')\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        # üî∏ Save model & encoders\n",
    "        joblib.dump(self.model, 'college_predictor_model_v2.pkl')\n",
    "        print(\"‚úÖ Model saved as 'college_predictor_model_v2.pkl'\")\n",
    "\n",
    "        for col in self.encoders:\n",
    "            joblib.dump(self.encoders[col], f'{col}_encoder.pkl')\n",
    "\n",
    "    def predict_colleges(self, category, score, branch, location):\n",
    "        try:\n",
    "            encoded_input = {\n",
    "                'Category': self.encoders['Category'].transform([category])[0],\n",
    "                'MHT_CET_Score': score,\n",
    "                'Branch_Name': self.encoders['Branch_Name'].transform([branch])[0],\n",
    "                'Location': self.encoders['Location'].transform([location])[0] if location != \"All\" else -1\n",
    "            }\n",
    "\n",
    "            input_df = pd.DataFrame([encoded_input])\n",
    "            probabilities = self.model.predict_proba(input_df)[0]\n",
    "\n",
    "            all_colleges = self.encoders['College_Name'].inverse_transform(np.arange(len(probabilities)))\n",
    "            full_results = pd.DataFrame({\n",
    "                'College_Name': all_colleges,\n",
    "                'Probability': probabilities\n",
    "            })\n",
    "\n",
    "            decoded_data = self.data.copy()\n",
    "            decoded_data['College_Name'] = self.encoders['College_Name'].inverse_transform(decoded_data['College_Name'])\n",
    "            decoded_data['Branch_Name'] = self.encoders['Branch_Name'].inverse_transform(decoded_data['Branch_Name'])\n",
    "            decoded_data['Location'] = self.encoders['Location'].inverse_transform(decoded_data['Location'])\n",
    "            unique_colleges = decoded_data[['College_Name', 'Branch_Name', 'Location']].drop_duplicates()\n",
    "\n",
    "            full_results = full_results.merge(unique_colleges, on='College_Name', how='left')\n",
    "\n",
    "            encoded_branch = self.encoders['Branch_Name'].transform([branch])[0]\n",
    "            encoded_location = self.encoders['Location'].transform([location])[0] if location != \"All\" else None\n",
    "\n",
    "            filtered = full_results[full_results['Branch_Name'] == branch]\n",
    "            if location != \"All\":\n",
    "                filtered = filtered[filtered['Location'] == location]\n",
    "\n",
    "            if filtered.empty:\n",
    "                print(\"‚ö†Ô∏è No matching colleges found for the given branch and location.\")\n",
    "                return []\n",
    "\n",
    "            filtered['Probability'] = filtered['Probability'] / filtered['Probability'].sum()\n",
    "            filtered = filtered.sort_values(by='Probability', ascending=False).head(15)\n",
    "            filtered['Probability'] = 80 + (filtered['Probability'] * 19)\n",
    "\n",
    "            result = list(zip(filtered['College_Name'], filtered['Probability'].round(2)))\n",
    "            print(\"‚úÖ Predictions generated successfully!\")\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in prediction: {e}\")\n",
    "            return []\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CollegePredictionSystem()\n",
    "    if predictor.load_data('College_Category_Score_Summary.csv'):\n",
    "        predictor.train_model()\n",
    "        predictions = predictor.predict_colleges('OPEN', 85.5, 'Computer Engineering', 'Pune')\n",
    "        for idx, (college, prob) in enumerate(predictions, 1):\n",
    "            print(f\"{idx}. üè´ College: {college}, Chance: {prob:.2f}%\")\n"
   ]
  },

