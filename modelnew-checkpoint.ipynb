{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec385f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\varun\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b2d3a0-0a6e-4e18-9a6f-92ad921bfac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error loading CSV file: [Errno 2] No such file or directory: 'College_Category_Score_Summary.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "class CollegePredictionSystem:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_data(self, csv_file):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding=\"windows-1252\", on_bad_lines='skip')\n",
    "\n",
    "            # Clean College_Name column\n",
    "            self.data['College_Name'] = self.data['College_Name'].str.strip()\n",
    "\n",
    "            required_columns = ['College_Name', 'Branch_Name', 'Location', 'OPEN_Score']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"‚ùå Error: Missing required columns: {missing_columns}\")\n",
    "                return False\n",
    "\n",
    "            print(f\"‚úÖ Successfully loaded {len(self.data)} records from {csv_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading CSV file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"‚ùå No data loaded. Please load data using load_data() first.\")\n",
    "\n",
    "        categorical_columns = ['Category', 'Branch_Name', 'College_Name', 'Location']\n",
    "        for col in categorical_columns:\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.data[col] = self.encoders[col].fit_transform(self.data[col].astype(str))\n",
    "\n",
    "        print(\"‚úÖ Data preprocessing completed!\")\n",
    "\n",
    "    def transform_scores_by_category(self):\n",
    "        score_columns = {\n",
    "            'OPEN': 'OPEN_Score',\n",
    "            'OBC': 'OBC_Score',\n",
    "            'SC': 'SC_Score',\n",
    "            'ST': 'ST_Score',\n",
    "            'SBC': 'SBC_Score',\n",
    "            'DT/VJ': 'DT/VJ_Score'\n",
    "        }\n",
    "\n",
    "        dfs = []\n",
    "        for category, col in score_columns.items():\n",
    "            temp_df = self.data[['College_Name', 'Branch_Name', 'Location', col]].copy()\n",
    "            temp_df = temp_df.rename(columns={col: 'MHT_CET_Score'})\n",
    "            temp_df['Category'] = category\n",
    "            temp_df = temp_df.dropna(subset=['MHT_CET_Score'])\n",
    "            dfs.append(temp_df)\n",
    "\n",
    "        self.data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.transform_scores_by_category()\n",
    "        self.preprocess_data()\n",
    "\n",
    "        features = ['Category', 'MHT_CET_Score', 'Branch_Name', 'Location']\n",
    "        target = 'College_Name'\n",
    "\n",
    "        X = self.data[features]\n",
    "        y = self.data[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        # üîπ Evaluation Metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"‚úÖ Model trained successfully with accuracy: {accuracy:.2f}\")\n",
    "\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        print(\"\\nüßæ Confusion Matrix:\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=False, cmap='Blues', fmt='d')\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        # üî∏ Save model & encoders\n",
    "        joblib.dump(self.model, 'college_predictor_model_v2.pkl')\n",
    "        print(\"‚úÖ Model saved as 'college_predictor_model_v2.pkl'\")\n",
    "\n",
    "        for col in self.encoders:\n",
    "            joblib.dump(self.encoders[col], f'{col}_encoder.pkl')\n",
    "\n",
    "    def predict_colleges(self, category, score, branch, location):\n",
    "        try:\n",
    "            encoded_input = {\n",
    "                'Category': self.encoders['Category'].transform([category])[0],\n",
    "                'MHT_CET_Score': score,\n",
    "                'Branch_Name': self.encoders['Branch_Name'].transform([branch])[0],\n",
    "                'Location': self.encoders['Location'].transform([location])[0] if location != \"All\" else -1\n",
    "            }\n",
    "\n",
    "            input_df = pd.DataFrame([encoded_input])\n",
    "            probabilities = self.model.predict_proba(input_df)[0]\n",
    "\n",
    "            all_colleges = self.encoders['College_Name'].inverse_transform(np.arange(len(probabilities)))\n",
    "            full_results = pd.DataFrame({\n",
    "                'College_Name': all_colleges,\n",
    "                'Probability': probabilities\n",
    "            })\n",
    "\n",
    "            decoded_data = self.data.copy()\n",
    "            decoded_data['College_Name'] = self.encoders['College_Name'].inverse_transform(decoded_data['College_Name'])\n",
    "            decoded_data['Branch_Name'] = self.encoders['Branch_Name'].inverse_transform(decoded_data['Branch_Name'])\n",
    "            decoded_data['Location'] = self.encoders['Location'].inverse_transform(decoded_data['Location'])\n",
    "            unique_colleges = decoded_data[['College_Name', 'Branch_Name', 'Location']].drop_duplicates()\n",
    "\n",
    "            full_results = full_results.merge(unique_colleges, on='College_Name', how='left')\n",
    "\n",
    "            encoded_branch = self.encoders['Branch_Name'].transform([branch])[0]\n",
    "            encoded_location = self.encoders['Location'].transform([location])[0] if location != \"All\" else None\n",
    "\n",
    "            filtered = full_results[full_results['Branch_Name'] == branch]\n",
    "            if location != \"All\":\n",
    "                filtered = filtered[filtered['Location'] == location]\n",
    "\n",
    "            if filtered.empty:\n",
    "                print(\"‚ö†Ô∏è No matching colleges found for the given branch and location.\")\n",
    "                return []\n",
    "\n",
    "            filtered['Probability'] = filtered['Probability'] / filtered['Probability'].sum()\n",
    "            filtered = filtered.sort_values(by='Probability', ascending=False).head(15)\n",
    "            filtered['Probability'] = 80 + (filtered['Probability'] * 19)\n",
    "\n",
    "            result = list(zip(filtered['College_Name'], filtered['Probability'].round(2)))\n",
    "            print(\"‚úÖ Predictions generated successfully!\")\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in prediction: {e}\")\n",
    "            return []\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CollegePredictionSystem()\n",
    "    if predictor.load_data('College_Category_Score_Summary.csv'):\n",
    "        predictor.train_model()\n",
    "        predictions = predictor.predict_colleges('OPEN', 85.5, 'Computer Engineering', 'Pune')\n",
    "        for idx, (college, prob) in enumerate(predictions, 1):\n",
    "            print(f\"{idx}. üè´ College: {college}, Chance: {prob:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8db06093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error loading CSV file: [Errno 2] No such file or directory: 'College_Category_Score_Summary.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "class CollegePredictionSystem:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_data(self, csv_file):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding=\"windows-1252\", on_bad_lines='skip')\n",
    "            self.data['College_Name'] = self.data['College_Name'].str.strip()\n",
    "\n",
    "            required_columns = ['College_Name', 'Branch_Name', 'Location', 'OPEN_Score']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"‚ùå Error: Missing required columns: {missing_columns}\")\n",
    "                return False\n",
    "\n",
    "            print(f\"‚úÖ Successfully loaded {len(self.data)} records from {csv_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading CSV file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"‚ùå No data loaded. Please load data using load_data() first.\")\n",
    "\n",
    "        categorical_columns = ['Category', 'Branch_Name', 'College_Name', 'Location']\n",
    "        for col in categorical_columns:\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.data[col] = self.encoders[col].fit_transform(self.data[col].astype(str))\n",
    "\n",
    "        print(\"‚úÖ Data preprocessing completed!\")\n",
    "\n",
    "    def transform_scores_by_category(self):\n",
    "        score_columns = {\n",
    "            'OPEN': 'OPEN_Score',\n",
    "            'OBC': 'OBC_Score',\n",
    "            'SC': 'SC_Score',\n",
    "            'ST': 'ST_Score',\n",
    "            'SBC': 'SBC_Score',\n",
    "            'DT/VJ': 'DT/VJ_Score'\n",
    "        }\n",
    "\n",
    "        dfs = []\n",
    "        for category, col in score_columns.items():\n",
    "            temp_df = self.data[['College_Name', 'Branch_Name', 'Location', col]].copy()\n",
    "            temp_df = temp_df.rename(columns={col: 'MHT_CET_Score'})\n",
    "            temp_df['Category'] = category\n",
    "            temp_df = temp_df.dropna(subset=['MHT_CET_Score'])\n",
    "            dfs.append(temp_df)\n",
    "\n",
    "        self.data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.transform_scores_by_category()\n",
    "        self.preprocess_data()\n",
    "\n",
    "        features = ['Category', 'MHT_CET_Score', 'Branch_Name', 'Location']\n",
    "        target = 'College_Name'\n",
    "\n",
    "        X = self.data[features]\n",
    "        y = self.data[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        # Evaluation\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\n‚úÖ Model trained with accuracy: {accuracy:.2f}\")\n",
    "\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # Confusion matrix and top-N analysis\n",
    "        unique_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "\n",
    "        # Top 10 most frequent classes in y_test\n",
    "        test_labels, counts = np.unique(y_test, return_counts=True)\n",
    "        top_10_classes = test_labels[np.argsort(counts)][-10:]\n",
    "\n",
    "        # Mapping top classes to confusion matrix indices\n",
    "        class_index_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "        top_indices = [class_index_map[label] for label in top_10_classes if label in class_index_map]\n",
    "        filtered_cm = cm[np.ix_(top_indices, top_indices)]\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(filtered_cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=top_10_classes, yticklabels=top_10_classes)\n",
    "        plt.title(\"Top 10 College Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        # Per-class accuracy report\n",
    "        per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "        college_names = self.encoders['College_Name'].inverse_transform(unique_labels)\n",
    "        accuracy_df = pd.DataFrame({\n",
    "            'College_Name': college_names,\n",
    "            'Accuracy (%)': (per_class_accuracy * 100).round(2)\n",
    "        }).sort_values(by='Accuracy (%)', ascending=False)\n",
    "\n",
    "        print(\"\\nüìà Top 10 Classes by Accuracy:\")\n",
    "        print(accuracy_df.head(10).to_string(index=False))\n",
    "\n",
    "        print(\"\\nüìâ Bottom 10 Classes by Accuracy:\")\n",
    "        print(accuracy_df.tail(10).to_string(index=False))\n",
    "\n",
    "        # Save model and encoders\n",
    "        joblib.dump(self.model, 'college_predictor_model_v2.pkl')\n",
    "        print(\"‚úÖ Model saved as 'college_predictor_model_v2.pkl'\")\n",
    "\n",
    "        for col in self.encoders:\n",
    "            joblib.dump(self.encoders[col], f'{col}_encoder.pkl')\n",
    "\n",
    "    def predict_colleges(self, category, score, branch, location):\n",
    "        try:\n",
    "            encoded_input = {\n",
    "                'Category': self.encoders['Category'].transform([category])[0],\n",
    "                'MHT_CET_Score': score,\n",
    "                'Branch_Name': self.encoders['Branch_Name'].transform([branch])[0],\n",
    "                'Location': self.encoders['Location'].transform([location])[0] if location != \"All\" else -1\n",
    "            }\n",
    "\n",
    "            input_df = pd.DataFrame([encoded_input])\n",
    "            probabilities = self.model.predict_proba(input_df)[0]\n",
    "\n",
    "            all_colleges = self.encoders['College_Name'].inverse_transform(np.arange(len(probabilities)))\n",
    "            full_results = pd.DataFrame({\n",
    "                'College_Name': all_colleges,\n",
    "                'Probability': probabilities\n",
    "            })\n",
    "\n",
    "            decoded_data = self.data.copy()\n",
    "            decoded_data['College_Name'] = self.encoders['College_Name'].inverse_transform(decoded_data['College_Name'])\n",
    "            decoded_data['Branch_Name'] = self.encoders['Branch_Name'].inverse_transform(decoded_data['Branch_Name'])\n",
    "            decoded_data['Location'] = self.encoders['Location'].inverse_transform(decoded_data['Location'])\n",
    "            unique_colleges = decoded_data[['College_Name', 'Branch_Name', 'Location']].drop_duplicates()\n",
    "\n",
    "            full_results = full_results.merge(unique_colleges, on='College_Name', how='left')\n",
    "\n",
    "            filtered = full_results[full_results['Branch_Name'] == branch]\n",
    "            if location != \"All\":\n",
    "                filtered = filtered[filtered['Location'] == location]\n",
    "\n",
    "            if filtered.empty:\n",
    "                print(\"‚ö†Ô∏è No matching colleges found for the given branch and location.\")\n",
    "                return []\n",
    "\n",
    "            filtered['Probability'] = filtered['Probability'] / filtered['Probability'].sum()\n",
    "            filtered = filtered.sort_values(by='Probability', ascending=False).head(15)\n",
    "            filtered['Probability'] = 80 + (filtered['Probability'] * 19)\n",
    "\n",
    "            result = list(zip(filtered['College_Name'], filtered['Probability'].round(2)))\n",
    "            print(\"‚úÖ Predictions generated successfully!\")\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in prediction: {e}\")\n",
    "            return []\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CollegePredictionSystem()\n",
    "    if predictor.load_data('College_Category_Score_Summary.csv'):\n",
    "        predictor.train_model()\n",
    "        predictions = predictor.predict_colleges('OPEN', 85.5, 'Computer Engineering', 'Pune')\n",
    "        for idx, (college, prob) in enumerate(predictions, 1):\n",
    "            print(f\"{idx}. üè´ College: {college}, Chance: {prob:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd82f45-4dec-46dd-8a76-d0a8789feb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error loading CSV file: [Errno 2] No such file or directory: 'College_Category_Score_Summary.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, \n",
    "    top_k_accuracy_score, log_loss, roc_auc_score, roc_curve, auc\n",
    ")\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "class CollegePredictionSystem:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_data(self, csv_file):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding=\"windows-1252\", on_bad_lines='skip')\n",
    "            self.data['College_Name'] = self.data['College_Name'].str.strip()\n",
    "\n",
    "            required_columns = ['College_Name', 'Branch_Name', 'Location', 'OPEN_Score']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"‚ùå Error: Missing required columns: {missing_columns}\")\n",
    "                return False\n",
    "\n",
    "            print(f\"‚úÖ Successfully loaded {len(self.data)} records from {csv_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading CSV file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"‚ùå No data loaded. Please load data using load_data() first.\")\n",
    "\n",
    "        categorical_columns = ['Category', 'Branch_Name', 'College_Name', 'Location']\n",
    "        for col in categorical_columns:\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.data[col] = self.encoders[col].fit_transform(self.data[col].astype(str))\n",
    "\n",
    "        print(\"‚úÖ Data preprocessing completed!\")\n",
    "\n",
    "    def transform_scores_by_category(self):\n",
    "        score_columns = {\n",
    "            'OPEN': 'OPEN_Score',\n",
    "            'OBC': 'OBC_Score',\n",
    "            'SC': 'SC_Score',\n",
    "            'ST': 'ST_Score',\n",
    "            'SBC': 'SBC_Score',\n",
    "            'DT/VJ': 'DT/VJ_Score'\n",
    "        }\n",
    "\n",
    "        dfs = []\n",
    "        for category, col in score_columns.items():\n",
    "            temp_df = self.data[['College_Name', 'Branch_Name', 'Location', col]].copy()\n",
    "            temp_df = temp_df.rename(columns={col: 'MHT_CET_Score'})\n",
    "            temp_df['Category'] = category\n",
    "            temp_df = temp_df.dropna(subset=['MHT_CET_Score'])\n",
    "            dfs.append(temp_df)\n",
    "\n",
    "        self.data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.transform_scores_by_category()\n",
    "        self.preprocess_data()\n",
    "\n",
    "        features = ['Category', 'MHT_CET_Score', 'Branch_Name', 'Location']\n",
    "        target = 'College_Name'\n",
    "\n",
    "        X = self.data[features]\n",
    "        y = self.data[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_proba = self.model.predict_proba(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\n‚úÖ Model trained with accuracy: {accuracy:.2f}\")\n",
    "\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        print(\"\\nüéØ Top-K Accuracy:\")\n",
    "        print(\"Top-1 Accuracy:\", top_k_accuracy_score(y_test, y_proba, k=1))\n",
    "        print(\"Top-5 Accuracy:\", top_k_accuracy_score(y_test, y_proba, k=5))\n",
    "\n",
    "        print(\"\\nüìâ Log Loss:\")\n",
    "        print(\"Log Loss:\", log_loss(y_test, y_proba))\n",
    "\n",
    "        all_classes = self.model.classes_\n",
    "        y_test_bin = label_binarize(y_test, classes=all_classes)\n",
    "        if y_test_bin.shape[1] != y_proba.shape[1]:\n",
    "            raise ValueError(\"Mismatch in number of classes between y_true and y_score. Check label encoding consistency.\")\n",
    "\n",
    "        print(\"\\nüìà ROC-AUC (OvR):\")\n",
    "        print(\"Macro AUC:\", roc_auc_score(y_test_bin, y_proba, average=\"macro\", multi_class=\"ovr\"))\n",
    "\n",
    "        unique_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "        test_labels, counts = np.unique(y_test, return_counts=True)\n",
    "        top_10_classes = test_labels[np.argsort(counts)][-10:]\n",
    "        class_index_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "        top_indices = [class_index_map[label] for label in top_10_classes if label in class_index_map]\n",
    "        filtered_cm = cm[np.ix_(top_indices, top_indices)]\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(filtered_cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=top_10_classes, yticklabels=top_10_classes)\n",
    "        plt.title(\"Top 10 College Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        for class_id in top_10_classes:\n",
    "            if class_id in all_classes:\n",
    "                class_idx = np.where(all_classes == class_id)[0][0]\n",
    "                fpr, tpr, _ = roc_curve(y_test_bin[:, class_idx], y_proba[:, class_idx])\n",
    "                roc_auc_i = auc(fpr, tpr)\n",
    "                plt.plot(fpr, tpr, label=f\"Class {class_id} (AUC={roc_auc_i:.2f})\")\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], \"k--\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curves for Top 10 Classes\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        joblib.dump(self.model, 'college_predictor_model_v2.pkl')\n",
    "        print(\"‚úÖ Model saved as 'college_predictor_model_v2.pkl'\")\n",
    "\n",
    "        for col in self.encoders:\n",
    "            joblib.dump(self.encoders[col], f'{col}_encoder.pkl')\n",
    "\n",
    "    def predict_colleges(self, category, score, branch, location):\n",
    "        try:\n",
    "            encoded_input = {\n",
    "                'Category': self.encoders['Category'].transform([category])[0],\n",
    "                'MHT_CET_Score': score,\n",
    "                'Branch_Name': self.encoders['Branch_Name'].transform([branch])[0],\n",
    "                'Location': self.encoders['Location'].transform([location])[0] if location != \"All\" else -1\n",
    "            }\n",
    "\n",
    "            input_df = pd.DataFrame([encoded_input])\n",
    "            probabilities = self.model.predict_proba(input_df)[0]\n",
    "\n",
    "            all_colleges = self.encoders['College_Name'].inverse_transform(np.arange(len(probabilities)))\n",
    "            full_results = pd.DataFrame({\n",
    "                'College_Name': all_colleges,\n",
    "                'Probability': probabilities\n",
    "            })\n",
    "\n",
    "            decoded_data = self.data.copy()\n",
    "            decoded_data['College_Name'] = self.encoders['College_Name'].inverse_transform(decoded_data['College_Name'])\n",
    "            decoded_data['Branch_Name'] = self.encoders['Branch_Name'].inverse_transform(decoded_data['Branch_Name'])\n",
    "            decoded_data['Location'] = self.encoders['Location'].inverse_transform(decoded_data['Location'])\n",
    "            unique_colleges = decoded_data[['College_Name', 'Branch_Name', 'Location']].drop_duplicates()\n",
    "\n",
    "            full_results = full_results.merge(unique_colleges, on='College_Name', how='left')\n",
    "\n",
    "            filtered = full_results[full_results['Branch_Name'] == branch]\n",
    "            if location != \"All\":\n",
    "                filtered = filtered[filtered['Location'] == location]\n",
    "\n",
    "            if filtered.empty:\n",
    "                print(\"‚ö†Ô∏è No matching colleges found for the given branch and location.\")\n",
    "                return []\n",
    "\n",
    "            filtered['Probability'] = filtered['Probability'] / filtered['Probability'].sum()\n",
    "            filtered = filtered.sort_values(by='Probability', ascending=False).head(15)\n",
    "            filtered['Probability'] = 80 + (filtered['Probability'] * 19)\n",
    "\n",
    "            result = list(zip(filtered['College_Name'], filtered['Probability'].round(2)))\n",
    "            print(\"‚úÖ Predictions generated successfully!\")\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in prediction: {e}\")\n",
    "            return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CollegePredictionSystem()\n",
    "    if predictor.load_data('College_Category_Score_Summary.csv'):\n",
    "        predictor.train_model()\n",
    "        predictions = predictor.predict_colleges('OPEN', 85.5, 'Computer Engineering', 'Pune')\n",
    "        for idx, (college, prob) in enumerate(predictions, 1):\n",
    "            print(f\"{idx}. üè´ College: {college}, Chance: {prob:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d4d0297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error loading CSV file: [Errno 2] No such file or directory: 'College_Category_Score_Summary.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    top_k_accuracy_score, roc_auc_score, roc_curve, auc, log_loss\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "class CollegePredictionSystem:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_data(self, csv_file):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding=\"windows-1252\", on_bad_lines='skip')\n",
    "            self.data['College_Name'] = self.data['College_Name'].str.strip()\n",
    "\n",
    "            required_columns = ['College_Name', 'Branch_Name', 'Location', 'OPEN_Score']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"‚ùå Error: Missing required columns: {missing_columns}\")\n",
    "                return False\n",
    "\n",
    "            print(f\"‚úÖ Successfully loaded {len(self.data)} records from {csv_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading CSV file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"‚ùå No data loaded. Please load data using load_data() first.\")\n",
    "\n",
    "        categorical_columns = ['Category', 'Branch_Name', 'College_Name', 'Location']\n",
    "        for col in categorical_columns:\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.data[col] = self.encoders[col].fit_transform(self.data[col].astype(str))\n",
    "\n",
    "        print(\"‚úÖ Data preprocessing completed!\")\n",
    "\n",
    "    def transform_scores_by_category(self):\n",
    "        score_columns = {\n",
    "            'OPEN': 'OPEN_Score',\n",
    "            'OBC': 'OBC_Score',\n",
    "            'SC': 'SC_Score',\n",
    "            'ST': 'ST_Score',\n",
    "            'SBC': 'SBC_Score',\n",
    "            'DT/VJ': 'DT/VJ_Score'\n",
    "        }\n",
    "\n",
    "        dfs = []\n",
    "        for category, col in score_columns.items():\n",
    "            temp_df = self.data[['College_Name', 'Branch_Name', 'Location', col]].copy()\n",
    "            temp_df = temp_df.rename(columns={col: 'MHT_CET_Score'})\n",
    "            temp_df['Category'] = category\n",
    "            temp_df = temp_df.dropna(subset=['MHT_CET_Score'])\n",
    "            dfs.append(temp_df)\n",
    "\n",
    "        self.data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.transform_scores_by_category()\n",
    "        self.preprocess_data()\n",
    "\n",
    "        features = ['Category', 'MHT_CET_Score', 'Branch_Name', 'Location']\n",
    "        target = 'College_Name'\n",
    "\n",
    "        X = self.data[features]\n",
    "        y = self.data[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_proba = self.model.predict_proba(X_test)\n",
    "\n",
    "        # Evaluation\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\n‚úÖ Model trained with accuracy: {accuracy:.2f}\")\n",
    "\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "        print(\"\\n=== Top-K Accuracy ===\")\n",
    "        print(\"Top-1 Accuracy:\", top_k_accuracy_score(y_test, y_proba, k=1))\n",
    "        print(\"Top-5 Accuracy:\", top_k_accuracy_score(y_test, y_proba, k=5))\n",
    "\n",
    "        print(\"\\n=== Log Loss ===\")\n",
    "        print(\"Log Loss:\", log_loss(y_test, y_proba))\n",
    "\n",
    "        # Confusion matrix and top-N analysis\n",
    "        unique_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "\n",
    "        # Top 10 most frequent classes in y_test\n",
    "        test_labels, counts = np.unique(y_test, return_counts=True)\n",
    "        top_10_classes = test_labels[np.argsort(counts)][-10:]\n",
    "\n",
    "        # Mapping top classes to confusion matrix indices\n",
    "        class_index_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "        top_indices = [class_index_map[label] for label in top_10_classes if label in class_index_map]\n",
    "        filtered_cm = cm[np.ix_(top_indices, top_indices)]\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(filtered_cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=top_10_classes, yticklabels=top_10_classes)\n",
    "        plt.title(\"Top 10 College Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        # ROC-AUC (One-vs-Rest)\n",
    "        y_bin = label_binarize(y_test, classes=unique_labels)\n",
    "        roc_auc = roc_auc_score(y_bin, y_proba, average=\"macro\", multi_class=\"ovr\")\n",
    "        print(\"\\n=== ROC-AUC (OvR): ===\")\n",
    "        print(f\"Macro ROC-AUC (OvR): {roc_auc:.3f}\")\n",
    "\n",
    "        # Plot ROC Curves\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        for idx, label in enumerate(unique_labels[:10]):  # Plot for top 10 classes\n",
    "            fpr, tpr, _ = roc_curve(y_bin[:, idx], y_proba[:, idx])\n",
    "            auc_score = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f\"Class {label} (AUC = {auc_score:.2f})\")\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], \"k--\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curves for Top 10 Classes\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "        # Save model and encoders\n",
    "        joblib.dump(self.model, 'college_predictor_model_v2.pkl')\n",
    "        print(\"‚úÖ Model saved as 'college_predictor_model_v2.pkl'\")\n",
    "\n",
    "        for col in self.encoders:\n",
    "            joblib.dump(self.encoders[col], f'{col}_encoder.pkl')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CollegePredictionSystem()\n",
    "    if predictor.load_data('College_Category_Score_Summary.csv'):\n",
    "        predictor.train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e02a77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Binarize the labels with consistent class order\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m y_test_bin \u001b[38;5;241m=\u001b[39m label_binarize(y_test, classes\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Plot ROC for top N classes (by support)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Binarize the labels with consistent class order\n",
    "y_test_bin = label_binarize(y_test, classes=model.classes_)\n",
    "\n",
    "# Plot ROC for top N classes (by support)\n",
    "N = 10\n",
    "top_classes = np.argsort(np.bincount(y_test))[-N:]  # top N most common class indices\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "for class_idx in top_classes:\n",
    "    if class_idx < y_proba.shape[1]:\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, class_idx], y_proba[:, class_idx])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"Class {class_idx} (AUC={roc_auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves for Top 10 Classes\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d0faf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix, \n",
    "    top_k_accuracy_score, log_loss, roc_auc_score, roc_curve, auc\n",
    ")\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "class CollegePredictionSystem:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_data(self, csv_file):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding=\"windows-1252\", on_bad_lines='skip')\n",
    "            self.data['College_Name'] = self.data['College_Name'].str.strip()\n",
    "\n",
    "            required_columns = ['College_Name', 'Branch_Name', 'Location', 'OPEN_Score']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"‚ùå Error: Missing required columns: {missing_columns}\")\n",
    "                return False\n",
    "\n",
    "            print(f\"‚úÖ Successfully loaded {len(self.data)} records from {csv_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading CSV file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"‚ùå No data loaded. Please load data using load_data() first.\")\n",
    "\n",
    "        categorical_columns = ['Category', 'Branch_Name', 'College_Name', 'Location']\n",
    "        for col in categorical_columns:\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.data[col] = self.encoders[col].fit_transform(self.data[col].astype(str))\n",
    "\n",
    "        print(\"‚úÖ Data preprocessing completed!\")\n",
    "\n",
    "    def transform_scores_by_category(self):\n",
    "        score_columns = {\n",
    "            'OPEN': 'OPEN_Score',\n",
    "            'OBC': 'OBC_Score',\n",
    "            'SC': 'SC_Score',\n",
    "            'ST': 'ST_Score',\n",
    "            'SBC': 'SBC_Score',\n",
    "            'DT/VJ': 'DT/VJ_Score'\n",
    "        }\n",
    "\n",
    "        dfs = []\n",
    "        for category, col in score_columns.items():\n",
    "            temp_df = self.data[['College_Name', 'Branch_Name', 'Location', col]].copy()\n",
    "            temp_df = temp_df.rename(columns={col: 'MHT_CET_Score'})\n",
    "            temp_df['Category'] = category\n",
    "            temp_df = temp_df.dropna(subset=['MHT_CET_Score'])\n",
    "            dfs.append(temp_df)\n",
    "\n",
    "        self.data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    def train_model(self):\n",
    "        self.transform_scores_by_category()\n",
    "        self.preprocess_data()\n",
    "\n",
    "        features = ['Category', 'MHT_CET_Score', 'Branch_Name', 'Location']\n",
    "        target = 'College_Name'\n",
    "\n",
    "        X = self.data[features]\n",
    "        y = self.data[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_proba = self.model.predict_proba(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\n‚úÖ Model trained with accuracy: {accuracy:.2f}\")\n",
    "\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        all_classes = self.model.classes_\n",
    "\n",
    "        print(\"\\nüéØ Top-K Accuracy:\")\n",
    "        print(\"Top-1 Accuracy:\", top_k_accuracy_score(y_test, y_proba, labels=all_classes, k=1))\n",
    "        print(\"Top-5 Accuracy:\", top_k_accuracy_score(y_test, y_proba, labels=all_classes, k=5))\n",
    "\n",
    "        print(\"\\nüìâ Log Loss:\")\n",
    "        print(\"Log Loss:\", log_loss(y_test, y_proba, labels=all_classes))\n",
    "\n",
    "    # One-hot encode y_test for ROC-AUC\n",
    "        y_test_bin = label_binarize(y_test, classes=all_classes)\n",
    "\n",
    "        print(\"\\nüìà ROC-AUC (OvR):\")\n",
    "        try:\n",
    "            macro_auc = roc_auc_score(y_test_bin, y_proba, average=\"macro\", multi_class=\"ovr\")\n",
    "            print(\"Macro AUC:\", macro_auc)\n",
    "        except ValueError as e:\n",
    "            print(f\"‚ö†Ô∏è ROC AUC Error: {e}\")\n",
    "\n",
    "    # Plot ROC for Top-N frequent classes\n",
    "        N = 10\n",
    "        top_classes = [label for label, _ in Counter(y_test).most_common(N)]\n",
    "        top_indices = [np.where(all_classes == label)[0][0] for label in top_classes if label in all_classes]\n",
    "\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        for idx in top_indices:\n",
    "            fpr, tpr, _ = roc_curve(y_test_bin[:, idx], y_proba[:, idx])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, label=f\"Class {self.encoders['College_Name'].inverse_transform([all_classes[idx]])[0]} (AUC={roc_auc:.2f})\")\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], \"k--\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"ROC Curves for Top 10 Most Frequent Colleges\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        joblib.dump(self.model, 'college_predictor_model_v2.pkl')\n",
    "        print(\"‚úÖ Model saved as 'college_predictor_model_v2.pkl'\")\n",
    "\n",
    "        for col in self.encoders:\n",
    "            joblib.dump(self.encoders[col], f'{col}_encoder.pkl')\n",
    "\n",
    "\n",
    "    def predict_colleges(self, category, score, branch, location):\n",
    "        try:\n",
    "            encoded_input = {\n",
    "                'Category': self.encoders['Category'].transform([category])[0],\n",
    "                'MHT_CET_Score': score,\n",
    "                'Branch_Name': self.encoders['Branch_Name'].transform([branch])[0],\n",
    "                'Location': self.encoders['Location'].transform([location])[0] if location != \"All\" else -1\n",
    "            }\n",
    "\n",
    "            input_df = pd.DataFrame([encoded_input])\n",
    "            probabilities = self.model.predict_proba(input_df)[0]\n",
    "\n",
    "            all_colleges = self.encoders['College_Name'].inverse_transform(np.arange(len(probabilities)))\n",
    "            full_results = pd.DataFrame({\n",
    "                'College_Name': all_colleges,\n",
    "                'Probability': probabilities\n",
    "            })\n",
    "\n",
    "            decoded_data = self.data.copy()\n",
    "            decoded_data['College_Name'] = self.encoders['College_Name'].inverse_transform(decoded_data['College_Name'])\n",
    "            decoded_data['Branch_Name'] = self.encoders['Branch_Name'].inverse_transform(decoded_data['Branch_Name'])\n",
    "            decoded_data['Location'] = self.encoders['Location'].inverse_transform(decoded_data['Location'])\n",
    "            unique_colleges = decoded_data[['College_Name', 'Branch_Name', 'Location']].drop_duplicates()\n",
    "\n",
    "            full_results = full_results.merge(unique_colleges, on='College_Name', how='left')\n",
    "\n",
    "            filtered = full_results[full_results['Branch_Name'] == branch]\n",
    "            if location != \"All\":\n",
    "                filtered = filtered[filtered['Location'] == location]\n",
    "\n",
    "            if filtered.empty:\n",
    "                print(\"‚ö†Ô∏è No matching colleges found for the given branch and location.\")\n",
    "                return []\n",
    "\n",
    "            filtered['Probability'] = filtered['Probability'] / filtered['Probability'].sum()\n",
    "            filtered = filtered.sort_values(by='Probability', ascending=False).head(15)\n",
    "            filtered['Probability'] = 80 + (filtered['Probability'] * 19)\n",
    "\n",
    "            result = list(zip(filtered['College_Name'], filtered['Probability'].round(2)))\n",
    "            print(\"‚úÖ Predictions generated successfully!\")\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in prediction: {e}\")\n",
    "            return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CollegePredictionSystem()\n",
    "    if predictor.load_data('College_Category_Score_Summary.csv'):\n",
    "        predictor.train_model()\n",
    "        predictions = predictor.predict_colleges('OPEN', 85.5, 'Computer Engineering', 'Pune')\n",
    "        for idx, (college, prob) in enumerate(predictions, 1):\n",
    "            print(f\"{idx}. üè´ College: {college}, Chance: {prob:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a6a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15399c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imbalanced-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from imblearn.under_sampling import RandomUnderSampler  # <-- added import\n",
    "\n",
    "\n",
    "class CollegePredictionSystem:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "        self.encoders = {}\n",
    "\n",
    "    def load_data(self, csv_file):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding=\"windows-1252\", on_bad_lines='skip')\n",
    "\n",
    "            # Clean College_Name column\n",
    "            self.data['College_Name'] = self.data['College_Name'].str.strip()\n",
    "\n",
    "            required_columns = ['College_Name', 'Branch_Name', 'Location', 'OPEN_Score']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"‚ùå Error: Missing required columns: {missing_columns}\")\n",
    "                return False\n",
    "\n",
    "            print(f\"‚úÖ Successfully loaded {len(self.data)} records from {csv_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading CSV file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"‚ùå No data loaded. Please load data using load_data() first.\")\n",
    "\n",
    "        categorical_columns = ['Category', 'Branch_Name', 'College_Name', 'Location']\n",
    "        for col in categorical_columns:\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.data[col] = self.encoders[col].fit_transform(self.data[col].astype(str))\n",
    "\n",
    "        print(\"‚úÖ Data preprocessing completed!\")\n",
    "\n",
    "    def transform_scores_by_category(self):\n",
    "        score_columns = {\n",
    "            'OPEN': 'OPEN_Score',\n",
    "            'OBC': 'OBC_Score',\n",
    "            'SC': 'SC_Score',\n",
    "            'ST': 'ST_Score',\n",
    "            'SBC': 'SBC_Score',\n",
    "            'DT/VJ': 'DT/VJ_Score'\n",
    "        }\n",
    "\n",
    "        dfs = []\n",
    "        for category, col in score_columns.items():\n",
    "            temp_df = self.data[['College_Name', 'Branch_Name', 'Location', col]].copy()\n",
    "            temp_df = temp_df.rename(columns={col: 'MHT_CET_Score'})\n",
    "            temp_df['Category'] = category\n",
    "            temp_df = temp_df.dropna(subset=['MHT_CET_Score'])\n",
    "            dfs.append(temp_df)\n",
    "\n",
    "        self.data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.transform_scores_by_category()\n",
    "        self.preprocess_data()\n",
    "\n",
    "        features = ['Category', 'MHT_CET_Score', 'Branch_Name', 'Location']\n",
    "        target = 'College_Name'\n",
    "\n",
    "        X = self.data[features]\n",
    "        y = self.data[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Apply undersampling on training data\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "        print(\"Before undersampling:\\n\", y_train.value_counts())\n",
    "        print(\"After undersampling:\\n\", y_train_res.value_counts())\n",
    "\n",
    "        # Train model on resampled data\n",
    "        self.model.fit(X_train_res, y_train_res)\n",
    "\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        # Evaluation Metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"‚úÖ Model trained successfully with accuracy: {accuracy:.2f}\")\n",
    "\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        print(\"\\nüßæ Confusion Matrix:\")\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=False, cmap='Blues', fmt='d')\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        # Save model & encoders\n",
    "        joblib.dump(self.model, 'college_predictor_model_v2.pkl')\n",
    "        print(\"‚úÖ Model saved as 'college_predictor_model_v2.pkl'\")\n",
    "\n",
    "        for col in self.encoders:\n",
    "            joblib.dump(self.encoders[col], f'{col}_encoder.pkl')\n",
    "\n",
    "    def predict_colleges(self, category, score, branch, location):\n",
    "        try:\n",
    "            encoded_input = {\n",
    "                'Category': self.encoders['Category'].transform([category])[0],\n",
    "                'MHT_CET_Score': score,\n",
    "                'Branch_Name': self.encoders['Branch_Name'].transform([branch])[0],\n",
    "                'Location': self.encoders['Location'].transform([location])[0] if location != \"All\" else -1\n",
    "            }\n",
    "\n",
    "            input_df = pd.DataFrame([encoded_input])\n",
    "            probabilities = self.model.predict_proba(input_df)[0]\n",
    "\n",
    "            all_colleges = self.encoders['College_Name'].inverse_transform(np.arange(len(probabilities)))\n",
    "            full_results = pd.DataFrame({\n",
    "                'College_Name': all_colleges,\n",
    "                'Probability': probabilities\n",
    "            })\n",
    "\n",
    "            decoded_data = self.data.copy()\n",
    "            decoded_data['College_Name'] = self.encoders['College_Name'].inverse_transform(decoded_data['College_Name'])\n",
    "            decoded_data['Branch_Name'] = self.encoders['Branch_Name'].inverse_transform(decoded_data['Branch_Name'])\n",
    "            decoded_data['Location'] = self.encoders['Location'].inverse_transform(decoded_data['Location'])\n",
    "            unique_colleges = decoded_data[['College_Name', 'Branch_Name', 'Location']].drop_duplicates()\n",
    "\n",
    "            full_results = full_results.merge(unique_colleges, on='College_Name', how='left')\n",
    "\n",
    "            # Note: you had a bug here - filtering by encoded values but comparing with original strings\n",
    "            # Fix: filter by original string columns to match user inputs\n",
    "            filtered = full_results[\n",
    "                (full_results['Branch_Name'] == branch)\n",
    "            ]\n",
    "            if location != \"All\":\n",
    "                filtered = filtered[filtered['Location'] == location]\n",
    "\n",
    "            if filtered.empty:\n",
    "                print(\"‚ö†Ô∏è No matching colleges found for the given branch and location.\")\n",
    "                return []\n",
    "\n",
    "            filtered['Probability'] = filtered['Probability'] / filtered['Probability'].sum()\n",
    "            filtered = filtered.sort_values(by='Probability', ascending=False).head(15)\n",
    "            filtered['Probability'] = 80 + (filtered['Probability'] * 19)\n",
    "\n",
    "            result = list(zip(filtered['College_Name'], filtered['Probability'].round(2)))\n",
    "            print(\"‚úÖ Predictions generated successfully!\")\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in prediction: {e}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CollegePredictionSystem()\n",
    "    if predictor.load_data('College_Category_Score_Summary.csv'):\n",
    "        predictor.train_model()\n",
    "        predictions = predictor.predict_colleges('OPEN', 85.5, 'Computer Engineering', 'Pune')\n",
    "        for idx, (college, prob) in enumerate(predictions, 1):\n",
    "            print(f\"{idx}. üè´ College: {college}, Chance: {prob:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a1a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "class CollegePredictionSystem:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "        self.encoders = {}\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def load_data(self, csv_file):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding=\"windows-1252\", on_bad_lines='skip')\n",
    "            self.data['College_Name'] = self.data['College_Name'].str.strip()\n",
    "\n",
    "            required_columns = ['College_Name', 'Branch_Name', 'Location', 'OPEN_Score']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"‚ùå Error: Missing required columns: {missing_columns}\")\n",
    "                return False\n",
    "\n",
    "            print(f\"‚úÖ Successfully loaded {len(self.data)} records from {csv_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading CSV file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def transform_scores_by_category(self):\n",
    "        score_columns = {\n",
    "            'OPEN': 'OPEN_Score',\n",
    "            'OBC': 'OBC_Score',\n",
    "            'SC': 'SC_Score',\n",
    "            'ST': 'ST_Score',\n",
    "            'SBC': 'SBC_Score',\n",
    "            'DT/VJ': 'DT/VJ_Score'\n",
    "        }\n",
    "\n",
    "        dfs = []\n",
    "        for category, col in score_columns.items():\n",
    "            if col not in self.data.columns:\n",
    "                # Skip if category score column does not exist\n",
    "                continue\n",
    "            temp_df = self.data[['College_Name', 'Branch_Name', 'Location', col]].copy()\n",
    "            temp_df = temp_df.rename(columns={col: 'MHT_CET_Score'})\n",
    "            temp_df['Category'] = category\n",
    "            temp_df = temp_df.dropna(subset=['MHT_CET_Score'])\n",
    "            dfs.append(temp_df)\n",
    "\n",
    "        self.data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"‚ùå No data loaded. Please load data using load_data() first.\")\n",
    "\n",
    "        categorical_columns = ['Category', 'Branch_Name', 'College_Name', 'Location']\n",
    "        for col in categorical_columns:\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.data[col] = self.encoders[col].fit_transform(self.data[col].astype(str))\n",
    "\n",
    "        # Scale MHT_CET_Score to 0-1 range\n",
    "        self.data['MHT_CET_Score'] = self.scaler.fit_transform(self.data[['MHT_CET_Score']])\n",
    "\n",
    "        print(\"‚úÖ Data preprocessing completed!\")\n",
    "\n",
    "    def train_model(self):\n",
    "        self.transform_scores_by_category()\n",
    "        self.preprocess_data()\n",
    "\n",
    "        features = ['Category', 'MHT_CET_Score', 'Branch_Name', 'Location']\n",
    "        target = 'College_Name'\n",
    "\n",
    "        X = self.data[features]\n",
    "        y = self.data[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        # Evaluation\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\n‚úÖ Model trained with accuracy: {accuracy:.2f}\")\n",
    "\n",
    "       # print(\"\\nüìä Classification Report:\")\n",
    "        #print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # Confusion matrix and top-N analysis\n",
    "        unique_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "\n",
    "        # Top 10 most frequent classes in y_test\n",
    "        test_labels, counts = np.unique(y_test, return_counts=True)\n",
    "        top_10_classes = test_labels[np.argsort(counts)][-10:]\n",
    "\n",
    "        # Mapping top classes to confusion matrix indices\n",
    "        class_index_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "        top_indices = [class_index_map[label] for label in top_10_classes if label in class_index_map]\n",
    "        filtered_cm = cm[np.ix_(top_indices, top_indices)]\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(filtered_cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=top_10_classes, yticklabels=top_10_classes)\n",
    "        plt.title(\"Top 10 College Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        # Per-class accuracy report\n",
    "        per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "        college_names = self.encoders['College_Name'].inverse_transform(unique_labels)\n",
    "        accuracy_df = pd.DataFrame({\n",
    "            'College_Name': college_names,\n",
    "            'Accuracy (%)': (per_class_accuracy * 100).round(2)\n",
    "        }).sort_values(by='Accuracy (%)', ascending=False)\n",
    "\n",
    "        print(\"\\nüìà Top 10 Classes by Accuracy:\")\n",
    "        print(accuracy_df.head(10).to_string(index=False))\n",
    "\n",
    "        print(\"\\nüìâ Bottom 10 Classes by Accuracy:\")\n",
    "        print(accuracy_df.tail(10).to_string(index=False))\n",
    "\n",
    "        # Save model, encoders, and scaler\n",
    "        joblib.dump(self.model, 'college_predictor_model_v2.pkl')\n",
    "        print(\"‚úÖ Model saved as 'college_predictor_model_v2.pkl'\")\n",
    "\n",
    "        for col in self.encoders:\n",
    "            joblib.dump(self.encoders[col], f'{col}_encoder.pkl')\n",
    "        joblib.dump(self.scaler, 'score_scaler.pkl')\n",
    "        print(\"‚úÖ Encoders and scaler saved.\")\n",
    "\n",
    "    def predict_colleges(self, category, score, branch, location):\n",
    "        try:\n",
    "            # Scale input score using saved scaler\n",
    "            scaled_score = self.scaler.transform([[score]])[0][0]\n",
    "\n",
    "            encoded_input = {\n",
    "                'Category': self.encoders['Category'].transform([category])[0],\n",
    "                'MHT_CET_Score': scaled_score,\n",
    "                'Branch_Name': self.encoders['Branch_Name'].transform([branch])[0],\n",
    "                # For 'All' location, do not filter on location (use a special value -1)\n",
    "                'Location': self.encoders['Location'].transform([location])[0] if location != \"All\" else -1\n",
    "            }\n",
    "\n",
    "            input_df = pd.DataFrame([encoded_input])\n",
    "            probabilities = self.model.predict_proba(input_df)[0]\n",
    "\n",
    "            all_colleges = self.encoders['College_Name'].inverse_transform(np.arange(len(probabilities)))\n",
    "            full_results = pd.DataFrame({\n",
    "                'College_Name': all_colleges,\n",
    "                'Probability': probabilities\n",
    "            })\n",
    "\n",
    "            # Decode other columns to join details\n",
    "            decoded_data = self.data.copy()\n",
    "            decoded_data['College_Name'] = self.encoders['College_Name'].inverse_transform(decoded_data['College_Name'])\n",
    "            decoded_data['Branch_Name'] = self.encoders['Branch_Name'].inverse_transform(decoded_data['Branch_Name'])\n",
    "            decoded_data['Location'] = self.encoders['Location'].inverse_transform(decoded_data['Location'])\n",
    "            unique_colleges = decoded_data[['College_Name', 'Branch_Name', 'Location']].drop_duplicates()\n",
    "\n",
    "            full_results = full_results.merge(unique_colleges, on='College_Name', how='left')\n",
    "\n",
    "            # Filter by branch and location (only if location != 'All')\n",
    "            filtered = full_results[full_results['Branch_Name'] == branch]\n",
    "            if location != \"All\":\n",
    "                filtered = filtered[filtered['Location'] == location]\n",
    "\n",
    "            if filtered.empty:\n",
    "                print(\"‚ö†Ô∏è No matching colleges found for the given branch and location.\")\n",
    "                return []\n",
    "\n",
    "            filtered['Probability'] = filtered['Probability'] / filtered['Probability'].sum()\n",
    "            filtered = filtered.sort_values(by='Probability', ascending=False).head(15)\n",
    "            filtered['Probability'] = 80 + (filtered['Probability'] * 19)  # Scale to 80-99 range\n",
    "\n",
    "            result = list(zip(filtered['College_Name'], filtered['Probability'].round(2)))\n",
    "            print(\"‚úÖ Predictions generated successfully!\")\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in prediction: {e}\")\n",
    "            return []\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CollegePredictionSystem()\n",
    "    if predictor.load_data('College_Category_Score_Summary.csv'):\n",
    "        predictor.train_model()\n",
    "        predictions = predictor.predict_colleges('OPEN', 85.5, 'Computer Engineering', 'Pune')\n",
    "        for idx, (college, prob) in enumerate(predictions, 1):\n",
    "            print(f\"{idx}. üè´ College: {college}, Chance: {prob:.2f}%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edafb84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load trained model (optional if you're using it in the same script)\n",
    "gbc_model = joblib.load('college_admission_model.pkl')\n",
    "\n",
    "# Predict probabilities\n",
    "y_score = gbc_model.predict_proba(X_test)\n",
    "\n",
    "# For multiclass, binarize the output labels\n",
    "lb = LabelBinarizer()\n",
    "y_test_binarized = lb.fit_transform(y_test)\n",
    "\n",
    "# Calculate ROC and AUC for each class, then average (macro)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = y_test_binarized.shape[1]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_binarized.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot the ROC curve (micro-average)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='GradientBoostingClassifier (AUC = {:.2f})'.format(roc_auc[\"micro\"]),\n",
    "         color='blue', linewidth=2)\n",
    "\n",
    "# Plot the random guessing line\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='black')\n",
    "\n",
    "# Plot settings\n",
    "plt.title('ROC Curve - Gradient Boosting Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb15113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, LabelBinarizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "class CollegePredictionSystem:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "        self.encoders = {}\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def load_data(self, csv_file):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding=\"windows-1252\", on_bad_lines='skip')\n",
    "            self.data['College_Name'] = self.data['College_Name'].str.strip()\n",
    "            required_columns = ['College_Name', 'Branch_Name', 'Location', 'OPEN_Score']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"‚ùå Error: Missing required columns: {missing_columns}\")\n",
    "                return False\n",
    "            print(f\"‚úÖ Successfully loaded {len(self.data)} records from {csv_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading CSV file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def transform_scores_by_category(self):\n",
    "        score_columns = {\n",
    "            'OPEN': 'OPEN_Score',\n",
    "            'OBC': 'OBC_Score',\n",
    "            'SC': 'SC_Score',\n",
    "            'ST': 'ST_Score',\n",
    "            'SBC': 'SBC_Score',\n",
    "            'DT/VJ': 'DT/VJ_Score'\n",
    "        }\n",
    "        dfs = []\n",
    "        for category, col in score_columns.items():\n",
    "            if col not in self.data.columns:\n",
    "                continue\n",
    "            temp_df = self.data[['College_Name', 'Branch_Name', 'Location', col]].copy()\n",
    "            temp_df = temp_df.rename(columns={col: 'MHT_CET_Score'})\n",
    "            temp_df['Category'] = category\n",
    "            temp_df = temp_df.dropna(subset=['MHT_CET_Score'])\n",
    "            dfs.append(temp_df)\n",
    "        self.data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"‚ùå No data loaded. Please load data using load_data() first.\")\n",
    "        categorical_columns = ['Category', 'Branch_Name', 'College_Name', 'Location']\n",
    "        for col in categorical_columns:\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.data[col] = self.encoders[col].fit_transform(self.data[col].astype(str))\n",
    "        self.data['MHT_CET_Score'] = self.scaler.fit_transform(self.data[['MHT_CET_Score']])\n",
    "        print(\"‚úÖ Data preprocessing completed!\")\n",
    "\n",
    "    def train_model(self):\n",
    "        self.transform_scores_by_category()\n",
    "        self.preprocess_data()\n",
    "        features = ['Category', 'MHT_CET_Score', 'Branch_Name', 'Location']\n",
    "        target = 'College_Name'\n",
    "        X = self.data[features]\n",
    "        y = self.data[target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\n‚úÖ Model trained with accuracy: {accuracy:.2f}\")\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        unique_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "        test_labels, counts = np.unique(y_test, return_counts=True)\n",
    "        top_10_classes = test_labels[np.argsort(counts)][-10:]\n",
    "        class_index_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "        top_indices = [class_index_map[label] for label in top_10_classes if label in class_index_map]\n",
    "        filtered_cm = cm[np.ix_(top_indices, top_indices)]\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(filtered_cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=top_10_classes, yticklabels=top_10_classes)\n",
    "        plt.title(\"Top 10 College Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "        per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "        college_names = self.encoders['College_Name'].inverse_transform(unique_labels)\n",
    "        accuracy_df = pd.DataFrame({\n",
    "            'College_Name': college_names,\n",
    "            'Accuracy (%)': (per_class_accuracy * 100).round(2)\n",
    "        }).sort_values(by='Accuracy (%)', ascending=False)\n",
    "        print(\"\\nüìà Top 10 Classes by Accuracy:\")\n",
    "        print(accuracy_df.head(10).to_string(index=False))\n",
    "        print(\"\\nüìâ Bottom 10 Classes by Accuracy:\")\n",
    "        print(accuracy_df.tail(10).to_string(index=False))\n",
    "        joblib.dump(self.model, 'college_predictor_model_v2.pkl')\n",
    "        print(\"‚úÖ Model saved as 'college_predictor_model_v2.pkl'\")\n",
    "        for col in self.encoders:\n",
    "            joblib.dump(self.encoders[col], f'{col}_encoder.pkl')\n",
    "        joblib.dump(self.scaler, 'score_scaler.pkl')\n",
    "        print(\"‚úÖ Encoders and scaler saved.\")\n",
    "\n",
    "    def predict_colleges(self, category, score, branch, location):\n",
    "        try:\n",
    "            scaled_score = self.scaler.transform([[score]])[0][0]\n",
    "            encoded_input = {\n",
    "                'Category': self.encoders['Category'].transform([category])[0],\n",
    "                'MHT_CET_Score': scaled_score,\n",
    "                'Branch_Name': self.encoders['Branch_Name'].transform([branch])[0],\n",
    "                'Location': self.encoders['Location'].transform([location])[0] if location != \"All\" else -1\n",
    "            }\n",
    "            input_df = pd.DataFrame([encoded_input])\n",
    "            probabilities = self.model.predict_proba(input_df)[0]\n",
    "            all_colleges = self.encoders['College_Name'].inverse_transform(np.arange(len(probabilities)))\n",
    "            full_results = pd.DataFrame({\n",
    "                'College_Name': all_colleges,\n",
    "                'Probability': probabilities\n",
    "            })\n",
    "            decoded_data = self.data.copy()\n",
    "            decoded_data['College_Name'] = self.encoders['College_Name'].inverse_transform(decoded_data['College_Name'])\n",
    "            decoded_data['Branch_Name'] = self.encoders['Branch_Name'].inverse_transform(decoded_data['Branch_Name'])\n",
    "            decoded_data['Location'] = self.encoders['Location'].inverse_transform(decoded_data['Location'])\n",
    "            unique_colleges = decoded_data[['College_Name', 'Branch_Name', 'Location']].drop_duplicates()\n",
    "            full_results = full_results.merge(unique_colleges, on='College_Name', how='left')\n",
    "            filtered = full_results[full_results['Branch_Name'] == branch]\n",
    "            if location != \"All\":\n",
    "                filtered = filtered[filtered['Location'] == location]\n",
    "            if filtered.empty:\n",
    "                print(\"‚ö†Ô∏è No matching colleges found for the given branch and location.\")\n",
    "                return []\n",
    "            filtered['Probability'] = filtered['Probability'] / filtered['Probability'].sum()\n",
    "            filtered = filtered.sort_values(by='Probability', ascending=False).head(15)\n",
    "            filtered['Probability'] = 80 + (filtered['Probability'] * 19)\n",
    "            result = list(zip(filtered['College_Name'], filtered['Probability'].round(2)))\n",
    "            print(\"‚úÖ Predictions generated successfully!\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in prediction: {e}\")\n",
    "            return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CollegePredictionSystem()\n",
    "    if predictor.load_data('College_Category_Score_Summary.csv'):\n",
    "        predictor.train_model()\n",
    "        predictions = predictor.predict_colleges('OPEN', 85.5, 'Computer Engineering', 'Pune')\n",
    "        for idx, (college, prob) in enumerate(predictions, 1):\n",
    "            print(f\"{idx}. üè´ College: {college}, Chance: {prob:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c7c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, LabelBinarizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "class CollegePredictionSystem:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.model = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
    "        self.encoders = {}\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def load_data(self, csv_file):\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file, encoding=\"windows-1252\", on_bad_lines='skip')\n",
    "            self.data['College_Name'] = self.data['College_Name'].str.strip()\n",
    "            required_columns = ['College_Name', 'Branch_Name', 'Location', 'OPEN_Score']\n",
    "            missing_columns = [col for col in required_columns if col not in self.data.columns]\n",
    "            if missing_columns:\n",
    "                print(f\"‚ùå Error: Missing required columns: {missing_columns}\")\n",
    "                return False\n",
    "            print(f\"‚úÖ Successfully loaded {len(self.data)} records from {csv_file}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading CSV file: {e}\")\n",
    "            return False\n",
    "\n",
    "    def transform_scores_by_category(self):\n",
    "        score_columns = {\n",
    "            'OPEN': 'OPEN_Score',\n",
    "            'OBC': 'OBC_Score',\n",
    "            'SC': 'SC_Score',\n",
    "            'ST': 'ST_Score',\n",
    "            'SBC': 'SBC_Score',\n",
    "            'DT/VJ': 'DT/VJ_Score'\n",
    "        }\n",
    "        dfs = []\n",
    "        for category, col in score_columns.items():\n",
    "            if col not in self.data.columns:\n",
    "                continue\n",
    "            temp_df = self.data[['College_Name', 'Branch_Name', 'Location', col]].copy()\n",
    "            temp_df = temp_df.rename(columns={col: 'MHT_CET_Score'})\n",
    "            temp_df['Category'] = category\n",
    "            temp_df = temp_df.dropna(subset=['MHT_CET_Score'])\n",
    "            dfs.append(temp_df)\n",
    "        self.data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"‚ùå No data loaded. Please load data using load_data() first.\")\n",
    "        categorical_columns = ['Category', 'Branch_Name', 'College_Name', 'Location']\n",
    "        for col in categorical_columns:\n",
    "            self.encoders[col] = LabelEncoder()\n",
    "            self.data[col] = self.encoders[col].fit_transform(self.data[col].astype(str))\n",
    "        self.data['MHT_CET_Score'] = self.scaler.fit_transform(self.data[['MHT_CET_Score']])\n",
    "        print(\"‚úÖ Data preprocessing completed!\")\n",
    "\n",
    "    def train_model(self):\n",
    "        self.transform_scores_by_category()\n",
    "        self.preprocess_data()\n",
    "        features = ['Category', 'MHT_CET_Score', 'Branch_Name', 'Location']\n",
    "        target = 'College_Name'\n",
    "        X = self.data[features]\n",
    "        y = self.data[target]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\n‚úÖ Model trained with accuracy: {accuracy:.2f}\")\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        #print(classification_report(y_test, y_pred))\n",
    "        unique_labels = np.unique(np.concatenate((y_test, y_pred)))\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "        test_labels, counts = np.unique(y_test, return_counts=True)\n",
    "        top_5_classes = test_labels[np.argsort(counts)][-5:]\n",
    "        class_index_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "        top_indices = [class_index_map[label] for label in top_5_classes if label in class_index_map]\n",
    "        filtered_cm = cm[np.ix_(top_indices, top_indices)]\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(filtered_cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=top_5_classes, yticklabels=top_5_classes)\n",
    "        plt.title(\"Top 5 College Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "        per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "        college_names = self.encoders['College_Name'].inverse_transform(unique_labels)\n",
    "        accuracy_df = pd.DataFrame({\n",
    "            'College_Name': college_names,\n",
    "            'Accuracy (%)': (per_class_accuracy * 100).round(2)\n",
    "        }).sort_values(by='Accuracy (%)', ascending=False)\n",
    "        print(\"\\nüìà Top 5 Classes by Accuracy:\")\n",
    "        print(accuracy_df.head(5).to_string(index=False))\n",
    "        print(\"\\nüìâ Bottom 5 Classes by Accuracy:\")\n",
    "        print(accuracy_df.tail(5).to_string(index=False))\n",
    "\n",
    "        # ROC Curve\n",
    "        lb = LabelBinarizer()\n",
    "        y_test_bin = lb.fit_transform(y_test)\n",
    "        if y_test_bin.shape[1] == 1:\n",
    "            y_test_bin = np.hstack((1 - y_test_bin, y_test_bin))\n",
    "        y_score = self.model.predict_proba(X_test)\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(y_test_bin.shape[1]):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for i in range(min(5, y_test_bin.shape[1])):\n",
    "            plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.title('ROC Curve (Top 5 Classes)')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        joblib.dump(self.model, 'college_predictor_model_v2.pkl')\n",
    "        print(\"‚úÖ Model saved as 'college_predictor_model_v2.pkl'\")\n",
    "        for col in self.encoders:\n",
    "            joblib.dump(self.encoders[col], f'{col}_encoder.pkl')\n",
    "        joblib.dump(self.scaler, 'score_scaler.pkl')\n",
    "        print(\"‚úÖ Encoders and scaler saved.\")\n",
    "\n",
    "    def predict_colleges(self, category, score, branch, location):\n",
    "        try:\n",
    "            scaled_score = self.scaler.transform([[score]])[0][0]\n",
    "            encoded_input = {\n",
    "                'Category': self.encoders['Category'].transform([category])[0],\n",
    "                'MHT_CET_Score': scaled_score,\n",
    "                'Branch_Name': self.encoders['Branch_Name'].transform([branch])[0],\n",
    "                'Location': self.encoders['Location'].transform([location])[0] if location != \"All\" else -1\n",
    "            }\n",
    "            input_df = pd.DataFrame([encoded_input])\n",
    "            probabilities = self.model.predict_proba(input_df)[0]\n",
    "            all_colleges = self.encoders['College_Name'].inverse_transform(np.arange(len(probabilities)))\n",
    "            full_results = pd.DataFrame({\n",
    "                'College_Name': all_colleges,\n",
    "                'Probability': probabilities\n",
    "            })\n",
    "            decoded_data = self.data.copy()\n",
    "            decoded_data['College_Name'] = self.encoders['College_Name'].inverse_transform(decoded_data['College_Name'])\n",
    "            decoded_data['Branch_Name'] = self.encoders['Branch_Name'].inverse_transform(decoded_data['Branch_Name'])\n",
    "            decoded_data['Location'] = self.encoders['Location'].inverse_transform(decoded_data['Location'])\n",
    "            unique_colleges = decoded_data[['College_Name', 'Branch_Name', 'Location']].drop_duplicates()\n",
    "            full_results = full_results.merge(unique_colleges, on='College_Name', how='left')\n",
    "            filtered = full_results[full_results['Branch_Name'] == branch]\n",
    "            if location != \"All\":\n",
    "                filtered = filtered[filtered['Location'] == location]\n",
    "            if filtered.empty:\n",
    "                print(\"‚ö†Ô∏è No matching colleges found for the given branch and location.\")\n",
    "                return []\n",
    "            filtered['Probability'] = filtered['Probability'] / filtered['Probability'].sum()\n",
    "            filtered = filtered.sort_values(by='Probability', ascending=False).head(15)\n",
    "            filtered['Probability'] = 80 + (filtered['Probability'] * 19)\n",
    "            result = list(zip(filtered['College_Name'], filtered['Probability'].round(2)))\n",
    "            print(\"‚úÖ Predictions generated successfully!\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in prediction: {e}\")\n",
    "            return []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    predictor = CollegePredictionSystem()\n",
    "    if predictor.load_data('College_Category_Score_Summary_new.csv'):\n",
    "        predictor.train_model()\n",
    "        predictions = predictor.predict_colleges('OPEN', 85.5, 'Computer Engineering', 'Pune')\n",
    "        for idx, (college, prob) in enumerate(predictions, 1):\n",
    "            print(f\"{idx}. üè´ College: {college}, Chance: {prob:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f7d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
